{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS Spam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faPW8FTXiH4b"
      },
      "outputs": [],
      "source": [
        "from keras.layers import SimpleRNN, Embedding, Dense, LSTM, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('spam.csv' , encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "gipDLSAujCIO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "labels =[]\n",
        "for i, label in enumerate(data['v1']):\n",
        "    texts.append(data['v2'][i])\n",
        "    if label == 'ham':\n",
        "        labels.append(0)\n",
        "    else:\n",
        "        labels.append(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "7XGqzQFrjMK0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = np.asarray(texts)\n",
        "labels = np.asarray(labels)"
      ],
      "metadata": {
        "id": "3dWrMlxlkV-G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "maxlen = 50"
      ],
      "metadata": {
        "id": "LItGe-STki0-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train,y_test = train_test_split(texts,labels,test_size = 0.25,random_state=42)"
      ],
      "metadata": {
        "id": "Zx6WbUjkkppy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "id": "miiofsROlQiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b99621-b7a7-4088-b341-edd2112bfa59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['U can call now...'\n",
            " 'Tell them u have a headache and just want to use 1 hour of sick time.'\n",
            " 'Never try alone to take the weight of a tear that comes out of ur heart and falls through ur eyes... Always remember a STUPID FRIEND is here to share... BSLVYL'\n",
            " ... \"Prabha..i'm soryda..realy..frm heart i'm sory\"\n",
            " 'Nt joking seriously i told' 'In work now. Going have in few min.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6h_G4VuJlag",
        "outputId": "b8dc16b2-3a85-455a-d365-eb37aa68735a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Funny fact Nobody teaches volcanoes 2 erupt, tsunamis 2 arise, hurricanes 2 sway aroundn no 1 teaches hw 2 choose a wife Natural disasters just happens'\n",
            " 'I sent my scores to sophas and i had to do secondary application for a few schools. I think if you are thinking of applying, do a research on cost also. Contact joke ogunrinde, her school is one me the less expensive ones'\n",
            " 'We know someone who you know that fancies you. Call 09058097218 to find out who. POBox 6, LS15HB 150p'\n",
            " ... 'Aiyah ok wat as long as got improve can already wat...'\n",
            " 'S:-)if we have one good partnership going we will take lead:)'\n",
            " 'did u get that message']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYV5fVpSJl98",
        "outputId": "1635ffdc-5c06-4bc5-e30a-b27038ce19a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0ethYgCJmOH",
        "outputId": "f93c5847-1171-4c20-9083-02c90e9a667c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)"
      ],
      "metadata": {
        "id": "bByfHYb_m8Gr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found {0} unique words:'.format(len(word_index)))"
      ],
      "metadata": {
        "id": "H_aNyPK4ndyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d38836a-66ef-4d8a-9a38-f62e93e7888f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7655 unique words:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences(sequences, maxlen = maxlen)"
      ],
      "metadata": {
        "id": "wO9UHD2Mn7tI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('data shape:', data.shape)"
      ],
      "metadata": {
        "id": "T-92ZPa7oH3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b5a644-36fe-44a2-a6f2-a0e44d36a872"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (5572, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-tYd9PUtoSXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fe2366-a22a-47bb-fda7-77c268e9261a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                6208      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326,273\n",
            "Trainable params: 326,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy',metrics = ['acc'])\n",
        "history_rnn = model.fit(x_train, y_train, epochs = 50, batch_size = 60, validation_split = 0.2)\n"
      ],
      "metadata": {
        "id": "DnmJU5M0phyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b543bf4-9f6b-4d8e-dafd-941286e182fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - 3s 22ms/step - loss: 0.4688 - acc: 0.7930 - val_loss: 0.3385 - val_acc: 0.8672\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.1951 - acc: 0.9387 - val_loss: 0.0912 - val_acc: 0.9809\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 0.0709 - acc: 0.9821 - val_loss: 0.0762 - val_acc: 0.9761\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0343 - acc: 0.9904 - val_loss: 0.0637 - val_acc: 0.9856\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0209 - acc: 0.9949 - val_loss: 0.0942 - val_acc: 0.9809\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0142 - acc: 0.9949 - val_loss: 0.0657 - val_acc: 0.9844\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0663 - val_acc: 0.9797\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0814 - val_acc: 0.9821\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0858 - val_acc: 0.9833\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0869 - val_acc: 0.9821\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.6502e-04 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9809\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 4.4413e-05 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9833\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 8.0710e-04 - acc: 0.9994 - val_loss: 0.1104 - val_acc: 0.9833\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.1907e-05 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9833\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 6.5451e-05 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9797\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 4.4044e-06 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9833\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0294 - acc: 0.9943 - val_loss: 0.1437 - val_acc: 0.9749\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 4.2346e-05 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9797\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 6.3876e-06 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9833\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.3897e-06 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9809\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.2964e-06 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9629\n",
            "Epoch 22/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.1733 - val_acc: 0.9749\n",
            "Epoch 23/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 3.8903e-06 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 0.9761\n",
            "Epoch 24/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 7.2411e-07 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 0.9821\n",
            "Epoch 25/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 4.5281e-06 - acc: 1.0000 - val_loss: 0.1873 - val_acc: 0.9737\n",
            "Epoch 26/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.0129e-06 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 0.9797\n",
            "Epoch 27/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.0024e-07 - acc: 1.0000 - val_loss: 0.1936 - val_acc: 0.9833\n",
            "Epoch 28/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 8.7613e-05 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.9809\n",
            "Epoch 29/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 8.5322e-08 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9833\n",
            "Epoch 30/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 5.9443e-08 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9833\n",
            "Epoch 31/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 3.3678e-08 - acc: 1.0000 - val_loss: 0.2182 - val_acc: 0.9821\n",
            "Epoch 32/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 3.1384e-07 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9797\n",
            "Epoch 33/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 3.8000e-08 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9821\n",
            "Epoch 34/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 6.0539e-04 - acc: 0.9997 - val_loss: 0.2246 - val_acc: 0.9797\n",
            "Epoch 35/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.2333e-08 - acc: 1.0000 - val_loss: 0.2245 - val_acc: 0.9797\n",
            "Epoch 36/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.1508e-08 - acc: 1.0000 - val_loss: 0.2229 - val_acc: 0.9797\n",
            "Epoch 37/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.0095e-08 - acc: 1.0000 - val_loss: 0.2172 - val_acc: 0.9785\n",
            "Epoch 38/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 9.1049e-09 - acc: 1.0000 - val_loss: 0.2190 - val_acc: 0.9809\n",
            "Epoch 39/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 5.2543e-09 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 0.9821\n",
            "Epoch 40/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 7.9442e-09 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 0.9809\n",
            "Epoch 41/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.5393e-04 - acc: 0.9997 - val_loss: 0.2243 - val_acc: 0.9785\n",
            "Epoch 42/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 7.6823e-08 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.9761\n",
            "Epoch 43/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 3.4480e-08 - acc: 1.0000 - val_loss: 0.2188 - val_acc: 0.9773\n",
            "Epoch 44/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.4680e-08 - acc: 1.0000 - val_loss: 0.2171 - val_acc: 0.9821\n",
            "Epoch 45/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 5.7928e-09 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9833\n",
            "Epoch 46/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 2.1726e-08 - acc: 1.0000 - val_loss: 0.2403 - val_acc: 0.9833\n",
            "Epoch 47/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 3.9537e-09 - acc: 1.0000 - val_loss: 0.2370 - val_acc: 0.9821\n",
            "Epoch 48/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 2.7124e-09 - acc: 1.0000 - val_loss: 0.2358 - val_acc: 0.9809\n",
            "Epoch 49/50\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.6051e-09 - acc: 1.0000 - val_loss: 0.2428 - val_acc: 0.9809\n",
            "Epoch 50/50\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 2.7284e-09 - acc: 1.0000 - val_loss: 0.2288 - val_acc: 0.9797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(x_test)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_test = pad_sequences(sequences_test, maxlen = maxlen)"
      ],
      "metadata": {
        "id": "d6wFDjphKfEd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_score = model.predict(x_test)"
      ],
      "metadata": {
        "id": "ZjpIvKcILgP5"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}